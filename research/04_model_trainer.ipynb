{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Cancer-Prediction-\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Cancer-Prediction-'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    important_features: List[str]\n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CancerPrediction.constants import *\n",
    "from CancerPrediction.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "        schema_filepath=SCHEMA_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        \n",
    "        create_directories([Path(self.config['artifacts_root'])])\n",
    "        \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config['model_trainer']\n",
    "        \n",
    "        create_directories([Path(config['root_dir'])])\n",
    "        \n",
    "        return ModelTrainerConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            train_data_path=Path(config['train_data_path']),\n",
    "            test_data_path=Path(config['test_data_path']),\n",
    "            model_name=config['model_name'],\n",
    "            important_features=config['important_features'],\n",
    "            target_column=config['target_column']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from ctgan import CTGAN\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from CancerPrediction import logger\n",
    "import torch\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    \n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig, seed: int = 42):\n",
    "        self.config = config\n",
    "        self.seed = seed\n",
    "        set_seed(self.seed)\n",
    "\n",
    "    def train(self):\n",
    "        # Cargar datos\n",
    "        train_data = pd.read_excel(self.config.train_data_path)\n",
    "\n",
    "        # Seleccionar características importantes\n",
    "        X_train = train_data[self.config.important_features]\n",
    "        y_train = train_data[self.config.target_column]\n",
    "\n",
    "        # Identificar clases minoritarias\n",
    "        class_counts = y_train.value_counts()\n",
    "        minority_classes = class_counts[class_counts < class_counts.median()].index\n",
    "\n",
    "        # Separar datos de clases minoritarias\n",
    "        X_minority = X_train[y_train.isin(minority_classes)]\n",
    "        y_minority = y_train[y_train.isin(minority_classes)]\n",
    "\n",
    "        # Entrenar el modelo CTGAN solo con las clases minoritarias\n",
    "        model = CTGAN(epochs=200)\n",
    "        model.fit(X_minority)\n",
    "\n",
    "        # Generar datos sintéticos para las clases minoritarias\n",
    "        synthetic_data_minority = model.sample(len(X_minority))\n",
    "\n",
    "        # Asignar etiquetas correctas a los datos sintéticos generados\n",
    "        synthetic_data_minority[self.config.target_column] = np.random.choice(minority_classes, len(synthetic_data_minority))\n",
    "\n",
    "        # Separar características y etiquetas de los datos sintéticos generados\n",
    "        X_synthetic = synthetic_data_minority[self.config.important_features]\n",
    "        y_synthetic = synthetic_data_minority[self.config.target_column]\n",
    "\n",
    "        # Combinar datos reales y datos sintéticos generados\n",
    "        X_combined = pd.concat([X_train, X_synthetic], axis=0)\n",
    "        y_combined = pd.concat([y_train, y_synthetic], axis=0)\n",
    "\n",
    "        # Aplicar SMOTE para sobremuestrear las clases minoritarias en el conjunto combinado\n",
    "        smote = SMOTE(random_state=self.seed)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_combined, y_combined)\n",
    "\n",
    "        # Dividir en conjuntos de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=self.seed, stratify=y_resampled)\n",
    "\n",
    "        # Definir los modelos individuales con regularización\n",
    "        rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=self.seed)\n",
    "        gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=self.seed)\n",
    "        lgbm_clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, num_leaves=31, random_state=self.seed)\n",
    "        xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=self.seed)\n",
    "\n",
    "        # Definir el Voting Classifier\n",
    "        voting_clf = VotingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', rf_clf),\n",
    "                ('gb', gb_clf),\n",
    "                ('lgbm', lgbm_clf),\n",
    "                ('xgb', xgb_clf)\n",
    "            ],\n",
    "            voting='soft'  # 'soft' uses predicted probabilities\n",
    "        )\n",
    "\n",
    "        # Entrenar el Voting Classifier con todos los datos resampleados\n",
    "        voting_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Guardar el modelo entrenado\n",
    "        joblib.dump(voting_clf, os.path.join(self.config.root_dir, self.config.model_name))\n",
    "\n",
    "        logger.info(f\"Model training completed and saved to {os.path.join(self.config.root_dir, self.config.model_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-27 09:53:25,252: INFO: 3124570509: >>>>> stage Model Training started <<<<<]\n",
      "[2024-06-27 09:53:25,257: INFO: common: YAML file: config\\config.yaml loaded successfully]\n",
      "[2024-06-27 09:53:25,259: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2024-06-27 09:53:25,264: INFO: common: YAML file: schema.yaml loaded successfully]\n",
      "[2024-06-27 09:53:25,266: INFO: common: Created directory at: artifacts]\n",
      "[2024-06-27 09:53:25,267: INFO: common: Created directory at: artifacts\\model_trainer]\n",
      "[2024-06-27 09:53:25,669: INFO: null: Guidance: There are no missing values in column sFas (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:25,731: INFO: null: Guidance: There are no missing values in column sHER2/sEGFR2/sErbB2 (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:25,863: INFO: null: Guidance: There are no missing values in column CA 15-3 (U/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:25,900: INFO: null: Guidance: There are no missing values in column CA19-9 (U/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:25,913: INFO: null: Guidance: There are no missing values in column CA-125 (U/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:25,947: INFO: null: Guidance: There are no missing values in column TIMP-2 (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,013: INFO: null: Guidance: There are no missing values in column TGFa (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,047: INFO: null: Guidance: There are no missing values in column Sex_1. Extra column not created.]\n",
      "[2024-06-27 09:53:26,063: INFO: null: Guidance: There are no missing values in column Leptin (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,114: INFO: null: Guidance: There are no missing values in column IL-8 (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,203: INFO: null: Guidance: There are no missing values in column IL-6 (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,274: INFO: null: Guidance: There are no missing values in column AFP (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,297: INFO: null: Guidance: There are no missing values in column GDF15 (ng/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,360: INFO: null: Guidance: There are no missing values in column Prolactin (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,421: INFO: null: Guidance: There are no missing values in column HGF (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,466: INFO: null: Guidance: There are no missing values in column CD44 (ng/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,531: INFO: null: Guidance: There are no missing values in column Midkine (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,603: INFO: null: Guidance: There are no missing values in column Thrombospondin-2 (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,663: INFO: null: Guidance: There are no missing values in column TIMP-1 (pg/ml). Extra column not created.]\n",
      "[2024-06-27 09:53:26,785: INFO: null: Guidance: There are no missing values in column HE4 (pg/ml). Extra column not created.]\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4847\n",
      "[LightGBM] [Info] Number of data points in the train set: 1747, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -2.076584\n",
      "[LightGBM] [Info] Start training from score -2.076584\n",
      "[LightGBM] [Info] Start training from score -2.081160\n",
      "[LightGBM] [Info] Start training from score -2.081160\n",
      "[LightGBM] [Info] Start training from score -2.081160\n",
      "[LightGBM] [Info] Start training from score -2.076584\n",
      "[LightGBM] [Info] Start training from score -2.081160\n",
      "[LightGBM] [Info] Start training from score -2.081160\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2024-06-27 09:53:55,796: INFO: 1129923373: Model training completed and saved to artifacts\\model_trainer\\model.joblib]\n",
      "[2024-06-27 09:53:55,796: INFO: 3124570509: >>>>> stage Model Training completed <<<<<\n",
      "\n",
      "x==========x]\n"
     ]
    }
   ],
   "source": [
    "STAGE_NAME = \"Model Training\"\n",
    "\n",
    "try:\n",
    "    logger.info(f\">>>>> stage {STAGE_NAME} started <<<<<\")\n",
    "    \n",
    "    # Inicializar el ConfigurationManager\n",
    "    config_manager = ConfigurationManager()\n",
    "    \n",
    "    # Obtener la configuración de entrenamiento del modelo\n",
    "    model_trainer_config = config_manager.get_model_trainer_config()\n",
    "    \n",
    "    # Crear instancia de ModelTrainer\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    \n",
    "    # Ejecutar el entrenamiento del modelo\n",
    "    model_trainer.train()\n",
    "    logger.info(f\">>>>> stage {STAGE_NAME} completed <<<<<\\n\\nx==========x\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.exception(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformation = r\"C:\\Cancer-Prediction-\\artifacts\\data_transformation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
