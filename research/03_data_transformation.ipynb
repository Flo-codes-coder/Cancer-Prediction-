{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Cancer-Prediction-\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Cancer-Prediction-'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-27 20:42:10,261: INFO: common: YAML file: config\\config.yaml loaded successfully]\n",
      "[2024-06-27 20:42:10,265: INFO: common: YAML file: params.yaml loaded successfully]\n",
      "[2024-06-27 20:42:10,270: INFO: common: YAML file: schema.yaml loaded successfully]\n",
      "[2024-06-27 20:42:10,272: INFO: common: Created directory at: artifacts]\n",
      "[2024-06-27 20:42:10,273: INFO: common: Created directory at: artifacts\\data_transformation]\n",
      "DataFrame loaded successfully:\n",
      "   Tumor type AJCC Stage  AFP (pg/ml)  Angiopoietin-2 (pg/ml)  AXL (pg/ml)  \\\n",
      "0  Colorectum          I     1583.450                 5598.50      3621.04   \n",
      "1  Colorectum          I      715.308                20936.35      2772.96   \n",
      "2  Colorectum         II     4365.530                 2350.93      4120.77   \n",
      "3  Colorectum         II      715.308                 1604.34      2029.96   \n",
      "4  Colorectum         II      801.300                 2087.57      2069.17   \n",
      "\n",
      "   CA-125 (U/ml)  CA 15-3 (U/ml)  CA19-9 (U/ml)  CD44 (ng/ml)  CEA (pg/ml)  \\\n",
      "0          5.090           19.08         16.452          9.81       540.07   \n",
      "1          7.270           10.04         40.910         27.57      5902.43   \n",
      "2          4.854           16.96         16.452         14.59       973.75   \n",
      "3          5.390            8.31         16.452          7.78      2027.53   \n",
      "4          4.854           11.73         16.452         12.21       614.49   \n",
      "\n",
      "   ...  sFas (pg/ml)  SHBG (nM)  sHER2/sEGFR2/sErbB2 (pg/ml)  \\\n",
      "0  ...       204.792      55.06                      6832.07   \n",
      "1  ...       204.792      72.92                      5549.47   \n",
      "2  ...       204.792     173.78                      3698.16   \n",
      "3  ...       204.792      29.47                      5856.00   \n",
      "4  ...       204.792      78.07                      5447.93   \n",
      "\n",
      "   sPECAM-1 (pg/ml)  TGFa (pg/ml)  Thrombospondin-2 (pg/ml)  TIMP-1 (pg/ml)  \\\n",
      "0           9368.53        16.086                  21863.74        56428.71   \n",
      "1           6224.55        16.086                  29669.66        73940.49   \n",
      "2           4046.48       179.030                   6020.47        22797.28   \n",
      "3           6121.93        16.086                   4331.02        20441.19   \n",
      "4           6982.32        16.086                   2311.91        56288.51   \n",
      "\n",
      "   TIMP-2 (pg/ml)  Omega score     Sex  \n",
      "0        39498.82     2.962820    Male  \n",
      "1        41277.09     2.445405  Female  \n",
      "2        28440.60     1.215758  Female  \n",
      "3        25896.73     1.640793  Female  \n",
      "4        49425.20     1.325771  Female  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "Data transformation completed successfully\n",
      "Training data saved to artifacts\\data_transformation\\train_df.xlsx\n",
      "Test data saved to artifacts\\data_transformation\\test_df.xlsx\n",
      "Transformation stage completed successfully\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    validated_data_file: Path\n",
    "    transformed_train_data_path: Path\n",
    "    transformed_test_data_path: Path\n",
    "    target_column: str\n",
    "    ordinal_features: List[str]\n",
    "    nominal_features: List[str]\n",
    "    \n",
    "\n",
    "from CancerPrediction.utils.common import read_yaml, create_directories\n",
    "from CancerPrediction.constants import *\n",
    "\n",
    "# Clase para gestionar la configuración\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH, schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        \n",
    "        create_directories([self.config['artifacts_root']])\n",
    "        \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config['data_transformation']\n",
    "        schema = self.schema['COLUMNS']\n",
    "        \n",
    "        create_directories([Path(config['root_dir'])])\n",
    "        \n",
    "        return DataTransformationConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            validated_data_file=Path(config['validated_data_file']),\n",
    "            transformed_train_data_path=Path(config['transformed_train_data_path']),\n",
    "            transformed_test_data_path=Path(config['transformed_test_data_path']),\n",
    "            target_column=config['target_column'],\n",
    "            ordinal_features=config['ordinal_features'],\n",
    "            nominal_features=config['nominal_features']\n",
    "        )\n",
    "\n",
    "        \n",
    "# src/CancerPrediction/pipeline/stages_03_data_transformation.py\n",
    "from CancerPrediction import logger\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# src/CancerPrediction/components/data_transformation.py\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from CancerPrediction import logger\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    validated_data_file: Path\n",
    "    transformed_train_data_path: Path\n",
    "    transformed_test_data_path: Path\n",
    "    target_column: str\n",
    "    ordinal_features: List[str]\n",
    "    nominal_features: List[str]\n",
    "\n",
    "# Implementar DataTransformation en una celda de notebook para prueba\n",
    "class DataTransformation:\n",
    "    def __init__(self, df: pd.DataFrame, config: DataTransformationConfig):\n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.label_encoders = {}\n",
    "    \n",
    "    def encode_labels(self):\n",
    "        # Codificar las características nominales usando LabelEncoder\n",
    "        for feature in self.config.nominal_features:\n",
    "            le = LabelEncoder()\n",
    "            self.df[feature] = le.fit_transform(self.df[feature])\n",
    "            self.label_encoders[feature] = le\n",
    "        \n",
    "        # Codificar la columna objetivo\n",
    "        le = LabelEncoder()\n",
    "        self.df[self.config.target_column] = le.fit_transform(self.df[self.config.target_column])\n",
    "        self.label_encoders[self.config.target_column] = le\n",
    "    \n",
    "    def get_preprocessor(self):\n",
    "        # Identificar características numéricas y categóricas\n",
    "        numeric_features = self.df.select_dtypes(include=[float, int]).columns.tolist()\n",
    "        ordinal_features = self.config.ordinal_features\n",
    "        nominal_features = self.config.nominal_features\n",
    "\n",
    "        # Eliminar las características ordinales, nominales y la columna objetivo de las características numéricas\n",
    "        numeric_features = [feature for feature in numeric_features if feature not in ordinal_features + nominal_features + [self.config.target_column]]\n",
    "\n",
    "        # Preprocesamiento para las características numéricas\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),  # Imputación con la mediana\n",
    "            ('scaler', StandardScaler())  # Estandarización\n",
    "        ])\n",
    "\n",
    "        # Preprocesamiento para las características categóricas ordinales\n",
    "        ordinal_transformer = Pipeline(steps=[\n",
    "            ('ordinal', OrdinalEncoder(dtype=int))  # Codificación Ordinal\n",
    "        ])\n",
    "\n",
    "        # Preprocesamiento para las características categóricas nominales (binarias)\n",
    "        nominal_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder(drop='if_binary', dtype=int))  # Codificación binaria\n",
    "        ])\n",
    "\n",
    "        # Combinación de los transformadores en un preprocesador\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('ord', ordinal_transformer, ordinal_features),\n",
    "                ('nom', nominal_transformer, nominal_features)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        \n",
    "        return preprocessor\n",
    "    \n",
    "    def transform(self):\n",
    "        # Crear directorio si no existe\n",
    "        self.config.transformed_train_data_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Codificar etiquetas\n",
    "        self.encode_labels()\n",
    "        \n",
    "        # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "        train_df, test_df = train_test_split(self.df, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Separar la columna objetivo para evitar que sea escalada\n",
    "        y_train = train_df.pop(self.config.target_column)\n",
    "        y_test = test_df.pop(self.config.target_column)\n",
    "        \n",
    "        preprocessor = self.get_preprocessor()\n",
    "        \n",
    "        # Aplicar la transformación\n",
    "        train_df_transformed = preprocessor.fit_transform(train_df)\n",
    "        test_df_transformed = preprocessor.transform(test_df)\n",
    "        \n",
    "        # Obtener los nombres de las columnas transformadas\n",
    "        numeric_features = preprocessor.transformers_[0][2]\n",
    "        ordinal_features = preprocessor.transformers_[1][2]\n",
    "        nominal_features = preprocessor.transformers_[2][2]\n",
    "        nominal_feature_names = preprocessor.transformers_[2][1]['onehot'].get_feature_names_out(nominal_features)\n",
    "        \n",
    "        # Combinar los nombres de las columnas transformadas\n",
    "        feature_names = np.concatenate([numeric_features, ordinal_features, nominal_feature_names])\n",
    "        \n",
    "        # Convertir los datos transformados en DataFrame con las columnas originales\n",
    "        train_df_transformed = pd.DataFrame(train_df_transformed, columns=feature_names)\n",
    "        test_df_transformed = pd.DataFrame(test_df_transformed, columns=feature_names)\n",
    "        \n",
    "        # Añadir de nuevo la columna objetivo a los DataFrames transformados\n",
    "        train_df_transformed[self.config.target_column] = y_train.values\n",
    "        test_df_transformed[self.config.target_column] = y_test.values\n",
    "        \n",
    "        # Guardar los conjuntos de datos de entrenamiento y prueba transformados en Excel\n",
    "        train_df_transformed.to_excel(self.config.transformed_train_data_path, index=False)\n",
    "        test_df_transformed.to_excel(self.config.transformed_test_data_path, index=False)\n",
    "        \n",
    "        print(\"Data transformation completed successfully\")\n",
    "        print(f\"Training data saved to {self.config.transformed_train_data_path}\")\n",
    "        print(f\"Test data saved to {self.config.transformed_test_data_path}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Inicializar el ConfigurationManager\n",
    "    config = ConfigurationManager()\n",
    "    \n",
    "    # Obtener la configuración de transformación de datos\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    \n",
    "    # Cargar datos desde el archivo validado\n",
    "    df = pd.read_excel(data_transformation_config.validated_data_file)\n",
    "    print(\"DataFrame loaded successfully:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Crear instancia de DataTransformation\n",
    "    data_transformation = DataTransformation(df, data_transformation_config)\n",
    "    \n",
    "    # Ejecutar la transformación completa\n",
    "    data_transformation.transform()\n",
    "    print(\"Transformation stage completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
